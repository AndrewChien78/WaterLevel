---
title: "River Water Level Prediction"
author: "Andrew Chien"
date: "December 27, 2018"
output:
  html_document:
    toc_depth: 4
---
This notebook shows how River Water Level Data from Edmonton Canada can be filtered, sorted, and cleaned.
Google Style Guide for R https://google.github.io/styleguide/Rguide.xml
(UpperCamelCase for functions, period.separated for variable names) is adopted for this document.


Dataset Source: https://data.edmonton.ca/dataset/Water-Levels-and-Flows/cnsu-iagr

Note: the original dataset has chunks of missing data, rows with water level = -1. The data should be reported back on a 5 minute interval.

## Setup
Loads all of the libraries required
```{r loadlibrary, include=FALSE}
library(dplyr)
library(tidyverse)
library(zoo)
library(xts)
library(lubridate)
```

Source files, files and directories
```{r loadfunctions}
input.datafile <- "data/Water_Levels_and_Flows.csv"
data.directory <- "/data/"
projPath <- "C:/Users/andre/Desktop/WaterLevel"
fcnFile <- "/water_level_fcn.R"
source(paste(projPath, fcnFile, sep=""))
```

## Set Global variables for this program
Note: Edmonton "05DF001" `Edmonton` not used as it has two records with identical time stamp.
```{r globalvariables}
station.name <- "atimCreek"
station.id <- "05EA012"
station.selectedmonths <- "2017-05"
```

## Data Import
Read the large `water.dataset` into R Environment. Note: The loading will take a minute or two as the file is 500MB in size. Note: We will not run this code chunk unless we are changing the variables above.
```{r loadwaterdata, eval=FALSE, include=FALSE}
water.dataset <- read.csv(input.datafile)
View(water.dataset)
```

## Data Tidying
This step is not needed as the dataset is already tidy (each column is a variable), each row is an observation.
</br>
</br>

## Data Transformation(DT)
### DT Part 1 - Narrow and Filter
Narrow, filter and store the selected River Water Level Station data(e.g. AtimCreek) into a dataset `station.data`
```{r get-stationdata, include=FALSE, eval=FALSE}
station.data <- filter(water.dataset, Station.Number == station.id)
```

Optional 1: Next we can choose to store the dataset in the CSV format using the `write.csv` function. The CSV format allows the dataset to be used for Python programs. Here are the commands for saving the if we want to store this dataset to disk, key in the following command:

We run the `rm` command to remove the large `water.dataset` from memory.
```{r save-stationdata, include=FALSE, eval=FALSE}
working.directory <- getwd()
write.csv(station.data, file=paste(working.directory, data.directory, station.name, ".csv", sep=""))
rm(water.dataset)
```
</br>
Optional 2: If we would like to load the dataset from a previous run, run the following lines:
```{r load-prevdata, echo=TRUE}
working.directory <- getwd()
station.data <- read.csv(file=paste(working.directory, data.directory, station.name, ".csv", sep=""))
head(station.data)
```

### DT - Part 2 - Select the columns needed
The commands below select only the Date and Time and Water level columns out of the `station.waterlevel` dataset. 
```{r select-columns}
station.unsortedwaterlevel<-select(station.data, Date.and.Time, Water.Level..m.)
head(station.unsortedwaterlevel)
```
</br>

### DT - Part 3 - Sorting
Next we need to sort the rows according to date and time to get the rows in order for us to convert `station.waterlevel` into a time series. Use the `POSIXct` function to do so as our column has both date and time. `station.sortedwaterlevel` is the new dataset that has been sorted according to time.
1 Feb 2019: Found out that we also need to take into account the AM and PM. Update the code to change the format option to `"%d/%m/%Y %I:%M:%S %p"`
```{r sortwaterlevel, echo=TRUE}
station.sortedwaterlevel <- station.unsortedwaterlevel[order(as.POSIXct(station.unsortedwaterlevel$Date.and.Time, format="%m/%d/%Y %I:%M:%S %p")), ]
write.csv(station.sortedwaterlevel, file=paste(working.directory, data.directory,station.name, "_sorted_water_level.csv", sep=""))
head(station.sortedwaterlevel)
```
</br>

### DT - Part 4 - Cleaning 
In this portion, I will first see where there is incomplete data. To this I will use the `group_by()` to group the data into months and calculate the completeness statistic of the data.

##### Missing Data
On 11 Jan 2019 Spent one two hours trying to figure out why subset was not working correctly. Just found out huge missing chunks of data for Nov 2016! Data from 2016-11-01 00:00:00 to 2016-11-01 01:00:00 missing.

31 Jan 2019: We will use the following code to detect if there is missing data in a particular month. We will group the water level info by month and summarise the number of records in each month and compare it against the number of supposed records per month.

We need to format the `station.sortedwaterlevel$Date.and.Time` which is of factor class into POSIXct class first.
```{r to-POSIXct-Class}
station.WLPOSIXct <- station.sortedwaterlevel
station.WLPOSIXct$Date.and.Time <- as.POSIXct(station.sortedwaterlevel$Date.and.Time, format="%m/%d/%Y %I:%M:%S %p")
head(station.WLPOSIXct)
```
<br>
Then we created a separate column using the substring `subtr()` function. The arguments `1,7` tells the function to only take the characters from 1 to 7 in the `Date.and.Time` column.
```{r add-month-year}
station.WLPOSIXct$month.year <- substr(station.WLPOSIXct$Date.and.Time, 1, 7)
head(station.WLPOSIXct)
```

<br>
Next we use the `groupy_by` and `summarise` with `mean, n()` functions to count the number of rows per month. 
<br>
As the water level data is reported by the telemetry station at 5 minutes intervals: <br>
For 31 days, if the data is complete, n = `r 60/5*24*31` <br>
For 30 days, n = `r 60/5*24*30` <br>
For 29 days, n = `r 60/5*24*29` <br>
For 28 days, n = `r 60/5*24*28` <br>
We store the results into a dataframe called `station.bymonth`. We also concatenate "-01" to the `month.year` column so we can calculate the no. of days in the month.
```{r grp-by-mth-completeness}
station.WLPOSIXct$no.of.days <- days_in_month(as.Date(station.WLPOSIXct$Date, format ="%Y-%m-%d"))
station.bymonth <- station.WLPOSIXct %>%
  group_by(month.year) %>%
  summarise(mean = mean(station.WLPOSIXct$Water.Level..m.), n = n())
station.bymonth$mean <- NULL
names(station.bymonth) <- c("month.year", "no.of.rows")
station.bymonth$no.of.days <- days_in_month(as.Date(paste(station.bymonth$month.year, "-01", sep=""), format="%Y-%m-%d"))
station.bymonth$completeness <- station.bymonth$no.of.rows / (station.bymonth$no.of.days * 288) * 100
head(station.bymonth)
```

<br>
For AtimCreek, from the table only May 2017, July and August 2018 has complete data. August 2018 and Oct 2018 had more than 100% data?. Some other months below show data that is above 90% completeness.
<br>
![](atimCreek_WL_completeness.png)

<br>
<br>

#### Taking just one month
We can use the `subset()` function to separate the data into months. A custom function called SubsetByMonth was written to do this repeatedly.
The function takes two arguments a dataframe, and the year month in the "YYYY-MM" format.
```{r subset-one-mth}
station.onemonth <- SubsetByMonth(station.WLPOSIXct,station.selectedmonths)
station.onemonth$month.year <- NULL
station.onemonth$no.of.days <- NULL
head(station.onemonth)
tail(station.onemonth)
str(station.onemonth)
write.csv(station.onemonth, file=paste(working.directory, data.directory,station.name,station.selectedmonths, ".csv", sep=""), row.names=FALSE)
```

<br>

#### Check for duplicated records 
1 Feb 2019: Found out that even though the records for one month seems complete, take for example May 2017(100%, 8928 rows), some of the rows were duplicated. We will use the `duplicate()` function identify and remove duplicates.
1 Feb 2019 4pm Update: Found out that duplication was caused by incorrect format declaration during sorting i.e. duplicated records were caused by the loss of AM and PM characters. 

```{r check-duplicates}
repeated.data <- station.onemonth$Date.and.Time[duplicated(station.onemonth$Date.and.Time)]
str(repeated.data)
head(repeated.data)
```
<br>
From the results, no duplicate records were found.


#### Invalid values (-1)
After plotting the sorted Water Level data, I noticed that there are some "-1" or invalid values.
<br>

```{r filter-neg-values}
station.negativewaterLevel <- filter(station.sortedwaterlevel, Water.Level..m. < 0 )
head(station.negativewaterLevel)
```
From the `station.negativewaterLevel` dataset, it seems that Nov 2016, Dec 2016, Jan 2017, May 2017, Dec 2017, Jan 2018, July 2018, August 2018 are the dates without -1 water level values.

For the conversion from the vector into a time series object we use the `ts()` function. The `ts()` function requires that the frequency and start time to be specified in year format. The start date is found at the first row of the `station.sortedwaterlevel` dataset. We will take that value and use that as a `begin.datetime` value. Note: the start year was previously manually calculated as _2016.7883652_
```{r to-time-series}
station.timeseries <- select(station.WLPOSIXct, Water.Level..m.)
begin.datetime <- station.WLPOSIXct[1,1]
station.timeseries <-ts(station.timeseries, frequency = 12*24*365, start=c(as.yearmon(begin.datetime)))
plot.ts(station.timeseries)
title(main=paste(station.name,"River Water Level as is",sep=" "))
```

These values needs to be cleaned up and these samples removed. After cleaning, 98 samples with -1.000 water level was removed. Note: the removed samples has cause truncation in the dataset.
```{r filter-negvalues}
station.cleanseries <- select(station.WLPOSIXct, Water.Level..m.)
station.cleanseries <- filter(station.cleanseries, Water.Level..m. > 0 )
station.cleantimeseries <-ts(station.cleanseries, frequency = 12*24*365, start=c(as.yearmon(begin.datetime)))
head(station.cleanseries)
```
Next we can convert the cleaned station water level data into a time series for time series analysis in R. We will need select only the datetime sorted `Water.Level..m.` column
```{r plot-timeseries, fig.cap="\\label{fig:figs} station.name"}
plot.ts(station.cleantimeseries)
title(main=paste(station.name,"River Water Level after removing -1s",sep=" "))
```

Next we are going to select just one month of data and try to predict 5 days of water level using the one month of data. We will choose a month where there are no missing values. We will use the `station.sortedwaterlevel` dataset to see which dates have missing values. 
#END
